import os
import cv2
import numpy as np
from PIL import Image
import base64
import io
import insightface
import mediapipe as mp
from enum import Enum
import json
import warnings


class FaceRegion(Enum):
    """é¢éƒ¨å€åŸŸå®šç¾©"""
    BRAIN = "è…¦"
    LUNG = "è‚º"
    HEART = "å¿ƒ"
    LIVER = "è‚"
    SPLEEN = "è„¾"
    LEFT_KIDNEY = "å·¦è…"
    RIGHT_KIDNEY = "å³è…"
    LEFT_STOMACH = "å·¦èƒƒ"
    RIGHT_STOMACH = "å³èƒƒ"
    LEFT_LONG = "å·¦å¤§è…¸"
    RIGHT_LONG = "å³å¤§è…¸"
    BLADDER = "è†€èƒ±"
    LEFT_EYE_WHITE = "å·¦çœ¼ç™½"
    RIGHT_EYE_WHITE = "å³çœ¼ç™½"
    CHIN = "ä¸‹å·´"


class SkinCondition(Enum):
    """è†šè‰²ç‹€æ…‹å®šç¾©"""
    NORMAL = "æ­£å¸¸"
    DARK = "ç™¼é»‘"
    RED = "ç™¼ç´…"
    PALE = "ç™¼ç™½"
    YELLOW = "ç™¼é»ƒ"
    CYAN = "ç™¼é’"


class FaceSkinAnalyzer:
    def __init__(self):
        self.face_app = None
        self.face_mesh = None
        self.diagnosis_results = {}
        self.face_regions = {}
        self.current_face_rect = None
        self.init_detector()

    def init_detector(self):
        """åˆå§‹åŒ–æª¢æ¸¬å™¨"""
        try:
            # æŠ‘åˆ¶è­¦å‘Š
            warnings.filterwarnings("ignore", message=".*CUDAExecutionProvider.*")

            # æª¢æŸ¥ PyTorch
            try:
                import torch
                cuda_available = torch.cuda.is_available()
                if cuda_available:
                    print("ğŸš€ æª¢æ¸¬åˆ°CUDAæ”¯æŒï¼Œä½¿ç”¨GPUåŠ é€Ÿ")
                    providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
                    ctx_id = 0
                else:
                    print("ğŸ’» ä½¿ç”¨CPUæ¨¡å¼é‹è¡Œ")
                    providers = ['CPUExecutionProvider']
                    ctx_id = -1
            except ImportError:
                print("âš ï¸  æœªå®‰è£ PyTorchï¼Œä½¿ç”¨ CPU æ¨¡å¼")
                providers = ['CPUExecutionProvider']
                ctx_id = -1

            # åˆå§‹åŒ– InsightFace
            try:
                self.face_app = insightface.app.FaceAnalysis(
                    name='buffalo_l',
                    providers=providers
                )
                self.face_app.prepare(ctx_id=ctx_id)
                print("âœ… InsightFace åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âŒ InsightFace åˆå§‹åŒ–å¤±æ•—: {e}")
                print("ğŸ’¡ å˜—è©¦åƒ…ä½¿ç”¨ CPU æ¨¡å¼...")
                self.face_app = insightface.app.FaceAnalysis(
                    name='buffalo_l',
                    providers=['CPUExecutionProvider']
                )
                self.face_app.prepare(ctx_id=-1)
                print("âœ… InsightFace CPU æ¨¡å¼åˆå§‹åŒ–æˆåŠŸ")

            # åˆå§‹åŒ– MediaPipe
            mp_face_mesh = mp.solutions.face_mesh
            self.face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, refine_landmarks=True)
            print("âœ… MediaPipe åˆå§‹åŒ–æˆåŠŸ")
            print("âœ… æª¢æ¸¬å™¨åˆå§‹åŒ–å®Œæˆ")
            return True

        except Exception as e:
            print(f"âŒ æª¢æ¸¬å™¨åˆå§‹åŒ–å¤±æ•—: {e}")
            return False

    def base64_to_image(self, base64_string):
        """å°‡base64å­—ç¬¦ä¸²è½‰æ›ç‚ºOpenCVåœ–åƒ"""
        try:
            if base64_string.startswith('data:image'):
                base64_string = base64_string.split(',')[1]

            image_data = base64.b64decode(base64_string)
            image_pil = Image.open(io.BytesIO(image_data))

            if image_pil.mode != 'RGB':
                image_pil = image_pil.convert('RGB')

            image_array = np.array(image_pil)
            image_bgr = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)
            return image_bgr
        except Exception as e:
            raise Exception(f"base64è½‰æ›åœ–åƒå¤±æ•—: {e}")

    def image_to_base64(self, image):
        """å°‡OpenCVåœ–åƒè½‰æ›ç‚ºbase64å­—ç¬¦ä¸²"""
        try:
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image_pil = Image.fromarray(image_rgb)

            buffer = io.BytesIO()
            image_pil.save(buffer, format='PNG')
            buffer.seek(0)

            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            return f"data:image/png;base64,{image_base64}"
        except Exception as e:
            raise Exception(f"åœ–åƒè½‰æ›base64å¤±æ•—: {e}")

    def safe_face_detection(self, image):
        """å®‰å…¨çš„äººè‡‰æª¢æ¸¬"""
        try:
            if self.face_app is None:
                return []
            faces = self.face_app.get(image)
            return faces if faces else []
        except Exception as e:
            print(f"âŒ äººè‡‰æª¢æ¸¬å¤±æ•—: {e}")
            return []

    def safe_mediapipe_detection(self, image_rgb):
        """å®‰å…¨çš„MediaPipeæª¢æ¸¬"""
        try:
            if self.face_mesh is None:
                return None
            results = self.face_mesh.process(image_rgb)
            return results
        except Exception as e:
            print(f"âŒ MediaPipe æª¢æ¸¬å¤±æ•—: {e}")
            return None

    def detect_faces_with_landmarks(self, image):
        """æª¢æ¸¬äººè‡‰ä¸¦è¿”å›ç‰¹å¾µé»"""
        h, w = image.shape[:2]
        img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # InsightFace åµæ¸¬äººè‡‰
        faces = self.safe_face_detection(image)
        if not faces:
            return []

        # MediaPipe åµæ¸¬ç´°ç¯€
        results = self.safe_mediapipe_detection(img_rgb)
        if not results or not results.multi_face_landmarks:
            return []

        landmarks = results.multi_face_landmarks[0]

        face_data = []
        for face in faces:
            bbox = face.bbox
            face_rect = {
                'left': int(bbox[0]),
                'top': int(bbox[1]),
                'width': int(bbox[2] - bbox[0]),
                'height': int(bbox[3] - bbox[1])
            }

            face_data.append({
                'rect': face_rect,
                'landmarks': landmarks,
                'image_size': (w, h)
            })

        return face_data

    def get_all_face_regions(self, landmarks, image_size):
        """ç²å–æ‰€æœ‰é¢éƒ¨å€åŸŸ"""
        w, h = image_size

        organ_landmarks = {
            FaceRegion.BRAIN: 10,
            FaceRegion.LUNG: 8,
            FaceRegion.HEART: 168,
            FaceRegion.LIVER: 197,
            FaceRegion.SPLEEN: 4,
            FaceRegion.LEFT_KIDNEY: 411,
            FaceRegion.RIGHT_KIDNEY: 187,
            FaceRegion.LEFT_STOMACH: 294,
            FaceRegion.RIGHT_STOMACH: 64,
            FaceRegion.LEFT_LONG: 330,
            FaceRegion.RIGHT_LONG: 101,
            FaceRegion.BLADDER: 164,
            FaceRegion.LEFT_EYE_WHITE: 33,
            FaceRegion.RIGHT_EYE_WHITE: 263,
            FaceRegion.CHIN: 175,
        }

        organ_crop_sizes = {
            FaceRegion.BRAIN: (80, 80),
            FaceRegion.LUNG: (20, 20),
            FaceRegion.HEART: (20, 20),
            FaceRegion.LIVER: (20, 20),
            FaceRegion.SPLEEN: (20, 20),
            FaceRegion.LEFT_KIDNEY: (20, 20),
            FaceRegion.RIGHT_KIDNEY: (20, 20),
            FaceRegion.LEFT_STOMACH: (20, 20),
            FaceRegion.RIGHT_STOMACH: (20, 20),
            FaceRegion.LEFT_LONG: (20, 20),
            FaceRegion.RIGHT_LONG: (20, 20),
            FaceRegion.BLADDER: (20, 20),
            FaceRegion.LEFT_EYE_WHITE: (30, 15),
            FaceRegion.RIGHT_EYE_WHITE: (30, 15),
            FaceRegion.CHIN: (40, 30),
        }

        regions = {}
        for organ, idx in organ_landmarks.items():
            pt = landmarks.landmark[idx]
            cx, cy = int(pt.x * w), int(pt.y * h)

            crop_w, crop_h = organ_crop_sizes.get(organ, (20, 20))
            x1 = max(cx - crop_w // 2, 0)
            y1 = max(cy - crop_h // 2, 0)
            x2 = min(cx + crop_w // 2, w)
            y2 = min(cy + crop_h // 2, h)

            regions[organ] = (x1, y1, x2 - x1, y2 - y1)

        return regions

    def analyze_skin_color_for_region(self, image, region_rect):
        """åˆ†æç‰¹å®šå€åŸŸçš„è†šè‰²"""
        x, y, w, h = region_rect

        x = max(0, x)
        y = max(0, y)
        w = min(image.shape[1] - x, w)
        h = min(image.shape[0] - y, h)

        if w <= 0 or h <= 0:
            return (153, 134, 117)

        region = image[y:y + h, x:x + w]
        blurred = cv2.GaussianBlur(region, (7, 7), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        avg_brightness = np.mean(hsv[:, :, 2])

        if avg_brightness < 50:
            lower_skin = np.array([0, 5, 20])
            upper_skin = np.array([40, 255, 255])
        else:
            lower_skin = np.array([0, 10, 40])
            upper_skin = np.array([40, 255, 255])

        skin_mask = cv2.inRange(hsv, lower_skin, upper_skin)

        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        skin_mask = cv2.morphologyEx(skin_mask, cv2.MORPH_CLOSE, kernel)
        skin_mask = cv2.morphologyEx(skin_mask, cv2.MORPH_OPEN, kernel)

        if cv2.countNonZero(skin_mask) < (w * h * 0.1):
            lower_skin_loose = np.array([0, 8, 30])
            upper_skin_loose = np.array([50, 255, 255])
            skin_mask = cv2.inRange(hsv, lower_skin_loose, upper_skin_loose)

            if cv2.countNonZero(skin_mask) == 0:
                skin_mask = np.ones((h, w), dtype=np.uint8) * 255

        skin_region = cv2.bitwise_and(blurred, blurred, mask=skin_mask)
        mean_color = cv2.mean(skin_region, skin_mask)

        return mean_color[:3]

    def diagnose_skin_condition(self, mean_color, region=None):
        """æ ¹æ“šRGBå€¼åˆ¤æ–·è†šè‰²ç‹€æ…‹"""
        b, g, r = mean_color

        # ç‰¹æ®Šè™•ç†çœ¼ç™½å€åŸŸ
        if region in [FaceRegion.LEFT_EYE_WHITE, FaceRegion.RIGHT_EYE_WHITE]:
            total_color = r + g + b
            if total_color > 0:
                yellow_ratio = (r + g) / (2 * total_color)
                blue_ratio = b / total_color

                if yellow_ratio > 0.6 and blue_ratio < 0.25 and g > 120:
                    return SkinCondition.YELLOW

            return SkinCondition.NORMAL

        # ä¸€èˆ¬è†šè‰²å€åŸŸè¨ºæ–·
        brightness = (r + g + b) / 3.0
        max_color = max(r, g, b)
        min_color = min(r, g, b)

        saturation = (max_color - min_color) / max_color if max_color > 0 else 0

        total_color = r + g + b
        if total_color > 0:
            red_ratio = r / total_color
            green_ratio = g / total_color
            blue_ratio = b / total_color
        else:
            red_ratio = green_ratio = blue_ratio = 0.33

        # åˆ¤æ–·è†šè‰²ç‹€æ…‹ - é™ä½ç´…è‰²æ•æ„Ÿåº¦
        if brightness < 70:
            return SkinCondition.DARK
        elif brightness > 200 and min_color > 150 and saturation < 0.1:
            return SkinCondition.PALE
        elif red_ratio > 0.48 and r > 170 and saturation > 0.15:
            return SkinCondition.RED
        elif (green_ratio > red_ratio and green_ratio > blue_ratio and
              green_ratio > 0.38 and g > 130):
            if red_ratio > 0.3:
                return SkinCondition.YELLOW
        elif (blue_ratio > red_ratio and blue_ratio > green_ratio and
              blue_ratio > 0.38 and b > 130):
            if green_ratio > 0.25:
                return SkinCondition.CYAN
        else:
            return SkinCondition.NORMAL

    def draw_face_regions(self, image):
        """åœ¨åœ–åƒä¸Šç¹ªè£½é¢éƒ¨å€åŸŸ"""
        if not self.face_regions:
            return image

        annotated_image = image.copy()

        condition_colors = {
            SkinCondition.NORMAL: (0, 255, 0),
            SkinCondition.DARK: (0, 0, 139),
            SkinCondition.RED: (0, 0, 255),
            SkinCondition.PALE: (255, 255, 255),
            SkinCondition.YELLOW: (0, 255, 255),
            SkinCondition.CYAN: (255, 255, 0)
        }

        for region, region_rect in self.face_regions.items():
            x, y, w, h = region_rect
            condition = self.diagnosis_results.get(region, SkinCondition.NORMAL)
            color = condition_colors.get(condition, (0, 255, 0))

            thickness = 3 if condition != SkinCondition.NORMAL else 2
            cv2.rectangle(annotated_image, (x, y), (x + w, y + h), color, thickness)

            label_text = region.value
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.4
            font_thickness = 1

            (text_width, text_height), baseline = cv2.getTextSize(label_text, font, font_scale, font_thickness)

            cv2.rectangle(annotated_image,
                          (x, y - text_height - 5),
                          (x + text_width + 5, y),
                          color, -1)

            text_color = (0, 0, 0) if condition in [SkinCondition.PALE, SkinCondition.YELLOW, SkinCondition.CYAN] else (
            255, 255, 255)
            cv2.putText(annotated_image, label_text, (x + 2, y - 2),
                        font, font_scale, text_color, font_thickness, cv2.LINE_AA)

        return annotated_image

    def draw_abnormal_regions_on_original(self, image):
        """åœ¨åŸåœ–ä¸Šåªæ¨™è¨»ç•°å¸¸å€åŸŸ"""
        if not self.face_regions:
            return image, 0

        annotated_image = image.copy()

        condition_colors = {
            SkinCondition.DARK: (0, 0, 139),
            SkinCondition.RED: (0, 0, 255),
            SkinCondition.PALE: (128, 128, 128),
            SkinCondition.YELLOW: (0, 255, 255),
            SkinCondition.CYAN: (255, 255, 0)
        }

        abnormal_count = 0
        for region, region_rect in self.face_regions.items():
            condition = self.diagnosis_results.get(region, SkinCondition.NORMAL)

            if condition == SkinCondition.NORMAL:
                continue

            abnormal_count += 1
            x, y, w, h = region_rect
            color = condition_colors.get(condition, (0, 0, 255))

            thickness = 4
            cv2.rectangle(annotated_image, (x, y), (x + w, y + h), color, thickness)

            label_text = f"{region.value}: {condition.value}"
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.6
            font_thickness = 2

            (text_width, text_height), baseline = cv2.getTextSize(label_text, font, font_scale, font_thickness)

            label_bg_height = text_height + 10
            label_bg_width = text_width + 10

            label_y = max(y - label_bg_height, label_bg_height)
            label_x = min(x, image.shape[1] - label_bg_width)

            cv2.rectangle(annotated_image,
                          (label_x, label_y - label_bg_height),
                          (label_x + label_bg_width, label_y),
                          color, -1)

            text_y = label_y - 5
            text_x = label_x + 5
            cv2.putText(annotated_image, label_text, (text_x, text_y),
                        font, font_scale, (255, 255, 255), font_thickness, cv2.LINE_AA)

        return annotated_image, abnormal_count

    def grid_analysis(self, image):
        """åœ–åƒæ ¼ç‹€åˆ†æ"""
        h, w = image.shape[:2]
        if h < 400 or w < 400:
            scale = max(400 / h, 400 / w)
            image = cv2.resize(image, (int(w * scale), int(h * scale)))

        grid_rows, grid_cols = 100, 100
        cell_h, cell_w = image.shape[0] // grid_rows, image.shape[1] // grid_cols
        avg_all = image.mean(axis=(0, 1)).astype(np.uint8)
        out_img = np.zeros_like(image)
        replace_img = image.copy()

        for row in range(grid_rows):
            for col in range(grid_cols):
                y1, y2 = row * cell_h, min((row + 1) * cell_h, image.shape[0])
                x1, x2 = col * cell_w, min((col + 1) * cell_w, image.shape[1])
                cell = image[y1:y2, x1:x2]
                if cell.size == 0:
                    continue
                avg = cell.mean(axis=(0, 1)).astype(np.uint8)
                bright = avg.mean()
                out_img[y1:y2, x1:x2] = avg
                if bright < 122:
                    cv2.rectangle(out_img, (x1, y1), (x2, y2), (0, 0, 255), 2)
                    replace_img[y1:y2, x1:x2] = avg_all

        for i in range(1, grid_rows):
            cv2.line(out_img, (0, i * cell_h), (image.shape[1], i * cell_h), (0, 0, 0), 1)
        for j in range(1, grid_cols):
            cv2.line(out_img, (j * cell_w, 0), (j * cell_w, image.shape[0]), (0, 0, 0), 1)

        return {
            'original': image,
            'grid': out_img,
            'dark_blocks': replace_img
        }

    def analyze_from_base64(self, base64_string):
        """å¾base64å­—ç¬¦ä¸²åˆ†æåœ–åƒ"""
        try:
            self.diagnosis_results.clear()
            self.face_regions.clear()
            self.current_face_rect = None

            image = self.base64_to_image(base64_string)
            face_data = self.detect_faces_with_landmarks(image)

            if not face_data:
                return {
                    "success": False,
                    "error": "æœªèƒ½æª¢æ¸¬åˆ°é¢éƒ¨ç‰¹å¾µé»ã€‚\n\nè«‹ç¢ºä¿ï¼š\nâ€¢ è‡‰éƒ¨å®Œæ•´ä¸”æ¸…æ™°å¯è¦‹\nâ€¢ å…‰ç·šå……è¶³ä¸”å‡å‹»\nâ€¢ é¿å…éæš—æˆ–é€†å…‰\nâ€¢ æ­£å°é¡é ­\n\nèª¿æ•´å¾Œé‡æ–°æ‹æ”æˆ–é¸æ“‡ç…§ç‰‡ã€‚",
                    "original_image": base64_string,
                    "annotated_image": None,
                    "abnormal_only_image": None,
                    "overall_color": None,
                    "region_results": None,
                    "grid_analysis": None
                }

            face_info = face_data[0]
            landmarks = face_info['landmarks']
            face_rect = face_info['rect']
            image_size = face_info['image_size']

            self.current_face_rect = (face_rect['left'], face_rect['top'],
                                      face_rect['width'], face_rect['height'])

            self.face_regions = self.get_all_face_regions(landmarks, image_size)

            # åˆ†ææ¯å€‹å€åŸŸ
            for region, region_rect in self.face_regions.items():
                mean_color = self.analyze_skin_color_for_region(image, region_rect)
                condition = self.diagnose_skin_condition(mean_color, region)
                self.diagnosis_results[region] = condition

            overall_color = self.analyze_skin_color_for_region(image, self.current_face_rect)
            annotated_image = self.draw_face_regions(image)
            abnormal_only_image, abnormal_count = self.draw_abnormal_regions_on_original(image)
            grid_results = self.grid_analysis(image)

            annotated_base64 = self.image_to_base64(annotated_image)
            abnormal_only_base64 = self.image_to_base64(abnormal_only_image)
            grid_base64 = self.image_to_base64(grid_results['grid'])
            dark_blocks_base64 = self.image_to_base64(grid_results['dark_blocks'])

            all_regions = {region.value: condition.value for region, condition in self.diagnosis_results.items()}
            abnormal_regions = {region.value: condition.value for region, condition in
                                self.diagnosis_results.items() if condition != SkinCondition.NORMAL}

            return {
                "success": True,
                "error": None,
                "original_image": base64_string,
                "annotated_image": annotated_base64,
                "abnormal_only_image": abnormal_only_base64,
                "abnormal_count": abnormal_count,
                "overall_color": {
                    "r": int(overall_color[2]),
                    "g": int(overall_color[1]),
                    "b": int(overall_color[0]),
                    "hex": f"#{int(overall_color[2]):02X}{int(overall_color[1]):02X}{int(overall_color[0]):02X}"
                },
                "all_region_results": all_regions,
                "region_results": abnormal_regions,
                "grid_analysis": {
                    "grid_image": grid_base64,
                    "dark_blocks_image": dark_blocks_base64
                }
            }

        except Exception as e:
            return {
                "success": False,
                "error": f"åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}",
                "original_image": base64_string,
                "annotated_image": None,
                "abnormal_only_image": None,
                "overall_color": None,
                "region_results": None,
                "grid_analysis": None
            }


def save_base64_image(base64_string, output_path):
    """å°‡base64å­—ç¬¦ä¸²ä¿å­˜ç‚ºåœ–åƒæ–‡ä»¶"""
    try:
        if base64_string.startswith('data:image'):
            base64_string = base64_string.split(',')[1]

        image_data = base64.b64decode(base64_string)

        with open(output_path, 'wb') as f:
            f.write(image_data)

        return True
    except Exception as e:
        print(f"ä¿å­˜åœ–åƒå¤±æ•—ï¼š{e}")
        return False


def check_dependencies():
    """æª¢æŸ¥ç³»çµ±ä¾è³´åŒ…å®‰è£æƒ…æ³"""


    dependencies = {
        'opencv-python': 'cv2',
        'numpy': 'numpy',
        'pillow': 'PIL',
        'insightface': 'insightface',
        'mediapipe': 'mediapipe'
    }

    missing_packages = []

    for package_name, import_name in dependencies.items():
        try:
            __import__(import_name)

        except ImportError:
            print(f"âŒ {package_name} - æœªå®‰è£")
            missing_packages.append(package_name)

    if missing_packages:
        print(f"\nâš ï¸  ç¼ºå°‘ä¾è³´åŒ…: {', '.join(missing_packages)}")
        print("\nğŸ’¡ å®‰è£å‘½ä»¤:")
        print("pip install " + " ".join(missing_packages))
        return False
    else:

        return True


def direct_face_analysis_and_annotation(input_folder="images", output_folder="face_analysis_results"):
    """
    ç›´æ¥åœ¨åŸåœ–ä¸Šè­˜åˆ¥å„å€‹å™¨å®˜éƒ¨ä½ä¸¦é€²è¡Œè†šè‰²åˆ†æ
    """
    print("=== é–‹å§‹ç›´æ¥é¢éƒ¨è†šè‰²åˆ†æèˆ‡æ¨™è¨» ===")

    # æª¢æŸ¥ä¾è³´åŒ…
    if not check_dependencies():
        print("âŒ è«‹å…ˆå®‰è£ç¼ºå°‘çš„ä¾è³´åŒ…å¾Œå†é‹è¡Œ")
        return {
            "success": False,
            "error": "ç¼ºå°‘å¿…è¦çš„ä¾è³´åŒ…",
            "processing_summary": {"total_images": 0, "successful_analyses": 0, "failed_analyses": 0}
        }

    os.makedirs(output_folder, exist_ok=True)

    # åˆå§‹åŒ–åˆ†æå™¨
    print("ğŸ”§ åˆå§‹åŒ–åˆ†æå™¨...")
    analyzer = FaceSkinAnalyzer()

    # æª¢æŸ¥åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
    if analyzer.face_app is None or analyzer.face_mesh is None:
        print("âŒ åˆ†æå™¨åˆå§‹åŒ–å¤±æ•—ï¼Œç„¡æ³•ç¹¼çºŒ")
        return {
            "success": False,
            "error": "åˆ†æå™¨åˆå§‹åŒ–å¤±æ•—",
            "processing_summary": {"total_images": 0, "successful_analyses": 0, "failed_analyses": 0}
        }

    # è™•ç†çµ±è¨ˆ
    success_count = 0
    fail_count = 0
    all_results = []

    print(f"ğŸ“ é–‹å§‹è™•ç† {input_folder} è³‡æ–™å¤¾ä¸­çš„åœ–åƒ...")

    # æª¢æŸ¥è¼¸å…¥è³‡æ–™å¤¾
    if not os.path.exists(input_folder):
        print(f"âŒ è¼¸å…¥è³‡æ–™å¤¾ä¸å­˜åœ¨: {input_folder}")
        return {
            "success": False,
            "error": f"è¼¸å…¥è³‡æ–™å¤¾ä¸å­˜åœ¨: {input_folder}",
            "processing_summary": {"total_images": 0, "successful_analyses": 0, "failed_analyses": 0}
        }

    # éæ­·åœ–åƒæ–‡ä»¶
    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

    if not image_files:
        print(f"âŒ {input_folder} è³‡æ–™å¤¾ä¸­æ²’æœ‰æ‰¾åˆ°åœ–åƒæ–‡ä»¶")
        return {
            "success": False,
            "error": "æ²’æœ‰æ‰¾åˆ°åœ–åƒæ–‡ä»¶",
            "processing_summary": {"total_images": 0, "successful_analyses": 0, "failed_analyses": 0}
        }

    print(f"ğŸ“Š æ‰¾åˆ° {len(image_files)} å€‹åœ–åƒæ–‡ä»¶")

    for filename in image_files:
        img_path = os.path.join(input_folder, filename)
        base_name = os.path.splitext(filename)[0]

        print(f"è™•ç†: {filename}")

        try:
            # è®€å–ä¸¦è½‰æ›åœ–åƒç‚ºbase64
            with open(img_path, 'rb') as f:
                image_data = f.read()

            base64_string = base64.b64encode(image_data).decode('utf-8')
            if filename.lower().endswith('.png'):
                base64_string = f"data:image/png;base64,{base64_string}"
            else:
                base64_string = f"data:image/jpeg;base64,{base64_string}"

            # åŸ·è¡Œé¢éƒ¨åˆ†æ
            result = analyzer.analyze_from_base64(base64_string)

            if result["success"]:
                success_count += 1

                # å‰µå»ºè©²åœ–åƒçš„è¼¸å‡ºè³‡æ–™å¤¾
                image_output_folder = os.path.join(output_folder, base_name)
                os.makedirs(image_output_folder, exist_ok=True)

                # ä¿å­˜åŸå§‹åœ–åƒ
                original_path = os.path.join(image_output_folder, f"{base_name}_original.jpg")
                with open(original_path, 'wb') as f:
                    f.write(image_data)

                # ä¿å­˜æ‰€æœ‰å€åŸŸæ¨™è¨»åœ–åƒ
                if result["annotated_image"]:
                    annotated_path = os.path.join(image_output_folder, f"{base_name}_all_regions_annotated.png")
                    save_base64_image(result["annotated_image"], annotated_path)

                # ä¿å­˜åªæ¨™è¨»ç•°å¸¸å€åŸŸçš„åœ–åƒ
                if result.get("abnormal_only_image"):
                    abnormal_only_path = os.path.join(image_output_folder, f"{base_name}_abnormal_only.png")
                    save_base64_image(result["abnormal_only_image"], abnormal_only_path)

                # ä¿å­˜æ ¼ç‹€åˆ†æåœ–åƒ
                if result["grid_analysis"]:
                    grid_folder = os.path.join(image_output_folder, "grid_analysis")
                    os.makedirs(grid_folder, exist_ok=True)

                    grid_path = os.path.join(grid_folder, f"{base_name}_grid.png")
                    dark_blocks_path = os.path.join(grid_folder, f"{base_name}_dark_blocks.png")

                    save_base64_image(result["grid_analysis"]["grid_image"], grid_path)
                    save_base64_image(result["grid_analysis"]["dark_blocks_image"], dark_blocks_path)

                # ä¿å­˜åˆ†æçµæœç‚ºJSON
                json_path = os.path.join(image_output_folder, f"{base_name}_analysis_result.json")
                with open(json_path, 'w', encoding='utf-8') as f:
                    # ç§»é™¤base64åœ–åƒæ•¸æ“šä»¥æ¸›å°JSONæ–‡ä»¶å¤§å°
                    result_copy = result.copy()
                    result_copy["original_image"] = None
                    result_copy["annotated_image"] = None
                    result_copy["abnormal_only_image"] = None
                    result_copy["grid_analysis"] = None

                    json.dump(result_copy, f, ensure_ascii=False, indent=2)

                print(f"  âœ… æˆåŠŸè™•ç†: {filename}")

                # é¡¯ç¤ºåˆ†æçµæœ
                if result.get("abnormal_count", 0) > 0:
                    print(f"    ç™¼ç¾ {result['abnormal_count']} å€‹ç•°å¸¸å€åŸŸ:")
                    for region, condition in result["region_results"].items():
                        print(f"      {region}: {condition}")
                else:
                    print(f"    âœ… æ‰€æœ‰å€åŸŸè†šè‰²ç‹€æ…‹æ­£å¸¸")

                # æ·»åŠ åˆ°ç¸½çµæœ
                all_results.append({
                    "filename": filename,
                    "success": True,
                    "abnormal_count": result.get("abnormal_count", 0),
                    "abnormal_regions": result["region_results"],
                    "all_regions": result["all_region_results"],
                    "overall_color": result["overall_color"],
                    "output_folder": image_output_folder
                })

            else:
                fail_count += 1
                print(f"  âŒ è™•ç†å¤±æ•—: {filename} - {result['error']}")

                all_results.append({
                    "filename": filename,
                    "success": False,
                    "error": result['error']
                })

        except Exception as e:
            fail_count += 1
            print(f"  âŒ è™•ç†å¤±æ•—: {filename} - {str(e)}")

            all_results.append({
                "filename": filename,
                "success": False,
                "error": str(e)
            })

    # ç”Ÿæˆçµ±è¨ˆæ•¸æ“š
    total_abnormal_regions = 0
    abnormal_images = []
    organ_statistics = {}

    for result in all_results:
        if result.get("success", False):
            abnormal_count = result.get("abnormal_count", 0)
            total_abnormal_regions += abnormal_count

            if abnormal_count > 0:
                abnormal_images.append(result)

            # çµ±è¨ˆå„å™¨å®˜ç•°å¸¸æƒ…æ³
            for region, condition in result.get("abnormal_regions", {}).items():
                if region not in organ_statistics:
                    organ_statistics[region] = {"count": 0, "conditions": {}}
                organ_statistics[region]["count"] += 1
                if condition not in organ_statistics[region]["conditions"]:
                    organ_statistics[region]["conditions"][condition] = 0
                organ_statistics[region]["conditions"][condition] += 1

    # ç”Ÿæˆæœ€çµ‚å ±å‘Š
    final_report = {
        "processing_summary": {
            "total_images": success_count + fail_count,
            "successful_analyses": success_count,
            "failed_analyses": fail_count,
            "success_rate": success_count / (success_count + fail_count) * 100 if (
                                                                                              success_count + fail_count) > 0 else 0
        },
        "analysis_summary": {
            "images_with_abnormalities": len(abnormal_images),
            "images_normal": success_count - len(abnormal_images),
            "total_abnormal_regions": total_abnormal_regions,
            "abnormality_rate": len(abnormal_images) / success_count * 100 if success_count > 0 else 0
        },
        "organ_statistics": organ_statistics,
        "abnormal_images": abnormal_images,
        "all_results": all_results,
        "output_folder": output_folder
    }

    # ä¿å­˜æœ€çµ‚å ±å‘Š
    report_path = os.path.join(output_folder, "face_analysis_final_report.json")
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(final_report, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… é¢éƒ¨è†šè‰²åˆ†æå®Œæˆï¼")
    print(f"ğŸ“Š è™•ç†çµ±è¨ˆ:")
    print(f"  - ç¸½åœ–åƒæ•¸: {success_count + fail_count}")
    print(f"  - æˆåŠŸåˆ†æ: {success_count}")
    print(f"  - åˆ†æå¤±æ•—: {fail_count}")
    print(f"  - æˆåŠŸç‡: {final_report['processing_summary']['success_rate']:.1f}%")
    print(f"  - æœ‰ç•°å¸¸çš„åœ–åƒ: {len(abnormal_images)}")
    print(f"  - æ­£å¸¸åœ–åƒ: {success_count - len(abnormal_images)}")
    print(f"  - ç¸½ç•°å¸¸å€åŸŸæ•¸: {total_abnormal_regions}")
    print(f"  - ç•°å¸¸ç‡: {final_report['analysis_summary']['abnormality_rate']:.1f}%")

    if organ_statistics:
        print(f"\nğŸ“‹ å™¨å®˜ç•°å¸¸çµ±è¨ˆ:")
        for organ, stats in organ_statistics.items():
            print(f"  - {organ}: {stats['count']} æ¬¡ç•°å¸¸")
            for condition, count in stats['conditions'].items():
                print(f"    â””â”€ {condition}: {count} æ¬¡")

    print(f"\nğŸ“ çµæœä¿å­˜åœ¨: {output_folder}")
    print(f"ğŸ“„ æœ€çµ‚å ±å‘Š: {report_path}")

    if abnormal_images:
        print(f"\nâš ï¸ ç™¼ç¾ç•°å¸¸çš„åœ–åƒ:")
        for img_result in abnormal_images[:10]:  # åªé¡¯ç¤ºå‰10å€‹
            filename = img_result['filename']
            abnormal_count = img_result['abnormal_count']
            abnormal_regions = img_result['abnormal_regions']
            print(f"  - {filename} ({abnormal_count} å€‹ç•°å¸¸å€åŸŸ):")
            for region, condition in abnormal_regions.items():
                print(f"    â””â”€ {region}: {condition}")

        if len(abnormal_images) > 10:
            print(f"  ... é‚„æœ‰ {len(abnormal_images) - 10} å¼µåœ–åƒæœ‰ç•°å¸¸ï¼ˆè©³è¦‹å ±å‘Šï¼‰")

    return final_report


def analyze_face_from_base64(base64_string):
    """ä¾¿æ·å‡½æ•¸ï¼šå¾base64å­—ç¬¦ä¸²åˆ†æé¢éƒ¨è†šè‰²"""
    analyzer = FaceSkinAnalyzer()
    return analyzer.analyze_from_base64(base64_string)


def analyze_face_from_file(file_path):
    """ä¾¿æ·å‡½æ•¸ï¼šå¾æ–‡ä»¶è·¯å¾‘åˆ†æé¢éƒ¨è†šè‰²"""
    try:
        # è®€å–åœ–åƒæ–‡ä»¶
        with open(file_path, 'rb') as f:
            image_data = f.read()

        # è½‰æ›ç‚ºbase64
        base64_string = base64.b64encode(image_data).decode('utf-8')

        # æ·»åŠ é©ç•¶çš„å‰ç¶´
        if file_path.lower().endswith('.png'):
            base64_string = f"data:image/png;base64,{base64_string}"
        elif file_path.lower().endswith(('.jpg', '.jpeg')):
            base64_string = f"data:image/jpeg;base64,{base64_string}"
        else:
            base64_string = f"data:image/png;base64,{base64_string}"

        # åˆ†æ
        analyzer = FaceSkinAnalyzer()
        return analyzer.analyze_from_base64(base64_string)

    except Exception as e:
        return {
            "success": False,
            "error": f"è®€å–æ–‡ä»¶å¤±æ•—ï¼š{str(e)}",
            "original_image": None,
            "annotated_image": None,
            "abnormal_only_image": None,
            "overall_color": None,
            "region_results": None,
            "grid_analysis": None
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æŠ‘åˆ¶ONNX Runtimeçš„CUDAè­¦å‘Š
    os.environ['OMP_NUM_THREADS'] = '1'
    warnings.filterwarnings("ignore", message=".*CUDAExecutionProvider.*")
    warnings.filterwarnings("ignore", message=".*onnxruntime.*")




    # æª¢æŸ¥è¼¸å…¥è³‡æ–™å¤¾
    if os.path.exists("images"):
        image_count = len([f for f in os.listdir('images') if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
        print(f"\nğŸ“ åµæ¸¬åˆ° 'images' è³‡æ–™å¤¾ï¼ŒåŒ…å« {image_count} å¼µåœ–åƒ")

        if image_count > 0:
            print("\nğŸš€ é–‹å§‹è‡ªå‹•åŸ·è¡Œé¢éƒ¨åˆ†ææµç¨‹...")

            # åŸ·è¡Œç›´æ¥é¢éƒ¨åˆ†æ
            final_result = direct_face_analysis_and_annotation(
                input_folder="images",
                output_folder="face_analysis_results"
            )

            if final_result.get("success", True):  # å¦‚æœæ²’æœ‰æ˜ç¢ºå¤±æ•—ï¼Œèªç‚ºæˆåŠŸ
                print(f"\nğŸ‰ é¢éƒ¨è†šè‰²åˆ†ææµç¨‹å®Œæˆ!")
            else:
                print(f"\nâŒ åˆ†æå¤±æ•—: {final_result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")

        else:
            print("ğŸ“‚ 'images' è³‡æ–™å¤¾ç‚ºç©ºï¼Œè«‹æ·»åŠ åœ–åƒæ–‡ä»¶å¾Œå†è©¦ã€‚")
    else:
        print("\nğŸ“‚ è«‹å…ˆå‰µå»º 'images' è³‡æ–™å¤¾ä¸¦æ”¾å…¥åœ–åƒæ–‡ä»¶ã€‚")
        print("ç„¶å¾Œé‡æ–°é‹è¡Œæ­¤è…³æœ¬ï¼Œç³»çµ±å°‡è‡ªå‹•åŸ·è¡Œ:")
        print("1. é¢éƒ¨å€åŸŸè­˜åˆ¥")
        print("2. è†šè‰²åˆ†æ")
        print("3. ç•°å¸¸æ¨™è¨»")
        print("4. ç”Ÿæˆå®Œæ•´å ±å‘Š")

