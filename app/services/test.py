import os
import cv2
import numpy as np
from PIL import Image
import base64
import io
import insightface
import mediapipe as mp
from enum import Enum
import json
import warnings


class FaceRegion(Enum):
    """é¢éƒ¨å€åŸŸå®šç¾©"""
    BRAIN = "è…¦"
    LUNG = "è‚º"
    HEART = "å¿ƒ"
    LIVER = "è‚"
    SPLEEN = "è„¾"
    LEFT_KIDNEY = "å·¦è…"
    RIGHT_KIDNEY = "å³è…"
    LEFT_STOMACH = "å·¦èƒƒ"
    RIGHT_STOMACH = "å³èƒƒ"
    LEFT_LONG = "å·¦å¤§è…¸"
    RIGHT_LONG = "å³å¤§è…¸"
    BLADDER = "è†€èƒ±"
    LEFT_EYE_WHITE = "å·¦çœ¼ç™½"
    RIGHT_EYE_WHITE = "å³çœ¼ç™½"
    CHIN = "ä¸‹å·´"


class SkinCondition(Enum):
    """è†šè‰²ç‹€æ…‹å®šç¾© - ç®€åŒ–ç‰ˆæœ¬"""
    NORMAL = "æ­£å¸¸"
    DARK = "ç™¼é»‘"
    RED = "ç™¼ç´…"
    PALE = "ç™¼ç™½"
    YELLOW = "ç™¼é»ƒ"
    CYAN_GREEN = "é’ç¶ "  # åç¶ çš„é’è‰²
    CYAN_BLACK = "é’é»‘"  # åé»‘çš„é’è‰²


class FaceSkinAnalyzer:
    def __init__(self):
        self.face_app = None
        self.face_mesh = None
        self.diagnosis_results = {}
        self.face_regions = {}
        self.current_face_rect = None
        self.init_detector()

    def get_face_position_description(self, region):
        """è·å–é¢éƒ¨åŒºåŸŸçš„å…·ä½“ä½ç½®æè¿°"""
        position_map = {
            FaceRegion.BRAIN: "é¢å¤´ä¸­å¤®",
            FaceRegion.LUNG: "é¢å¤´ä¸Šæ–¹",
            FaceRegion.HEART: "çœ‰å¿ƒåŒºåŸŸ",
            FaceRegion.LIVER: "å³çœ‰å¤–ä¾§",
            FaceRegion.SPLEEN: "é¼»æ¢ä¸Šæ–¹",
            FaceRegion.LEFT_KIDNEY: "å·¦å¤ªé˜³ç©´",
            FaceRegion.RIGHT_KIDNEY: "å³å¤ªé˜³ç©´",
            FaceRegion.LEFT_STOMACH: "å·¦è„¸é¢Šä¸Šæ–¹",
            FaceRegion.RIGHT_STOMACH: "å³è„¸é¢Šä¸Šæ–¹",
            FaceRegion.LEFT_LONG: "å·¦è„¸é¢Šä¸‹æ–¹",
            FaceRegion.RIGHT_LONG: "å³è„¸é¢Šä¸‹æ–¹",
            FaceRegion.BLADDER: "äººä¸­åŒºåŸŸ",
            FaceRegion.LEFT_EYE_WHITE: "å·¦çœ¼ç™½",
            FaceRegion.RIGHT_EYE_WHITE: "å³çœ¼ç™½",
            FaceRegion.CHIN: "ä¸‹å·´"
        }
        return position_map.get(region, region.value)

    def init_detector(self):
        """åˆå§‹åŒ–æª¢æ¸¬å™¨"""
        try:
            # å±è”½æ‰€æœ‰è­¦å‘Šå’Œæ—¥å¿—ä¿¡æ¯
            warnings.filterwarnings("ignore", message=".*CUDAExecutionProvider.*")
            warnings.filterwarnings("ignore", message=".*rcond.*")
            warnings.filterwarnings("ignore", category=FutureWarning)
            warnings.filterwarnings("ignore", category=UserWarning)

            # å±è”½TensorFlowå’ŒONNXä¿¡æ¯
            os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
            os.environ['GLOG_minloglevel'] = '3'  # å±è”½ONNX Runtimeæ—¥å¿—

            # å±è”½æ ‡å‡†è¾“å‡ºä¸­çš„æ¨¡å‹åŠ è½½ä¿¡æ¯
            import sys
            import contextlib
            from io import StringIO

            try:
                import torch
                cuda_available = torch.cuda.is_available()
                if cuda_available:
                    print("ğŸš€ æª¢æ¸¬åˆ°CUDAæ”¯æŒï¼Œä½¿ç”¨GPUåŠ é€Ÿ")
                    providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
                    ctx_id = 0
                else:
                    print("ğŸ’» ä½¿ç”¨CPUæ¨¡å¼é‹è¡Œ")
                    providers = ['CPUExecutionProvider']
                    ctx_id = -1
            except ImportError:
                print("âš ï¸  æœªå®‰è£ PyTorchï¼Œä½¿ç”¨ CPU æ¨¡å¼")
                providers = ['CPUExecutionProvider']
                ctx_id = -1

            try:
                # ä¸´æ—¶å±è”½æ ‡å‡†è¾“å‡ºæ¥éšè—æ¨¡å‹åŠ è½½ä¿¡æ¯
                f = StringIO()
                with contextlib.redirect_stdout(f):
                    self.face_app = insightface.app.FaceAnalysis(
                        name='buffalo_l',
                        providers=providers
                    )
                    self.face_app.prepare(ctx_id=ctx_id)

            except Exception as e:
                print(f"âŒ InsightFace åˆå§‹åŒ–å¤±æ•—: {e}")
                print("ğŸ’¡ å˜—è©¦åƒ…ä½¿ç”¨ CPU æ¨¡å¼...")
                f = StringIO()
                with contextlib.redirect_stdout(f):
                    self.face_app = insightface.app.FaceAnalysis(
                        name='buffalo_l',
                        providers=['CPUExecutionProvider']
                    )
                    self.face_app.prepare(ctx_id=-1)


            mp_face_mesh = mp.solutions.face_mesh
            self.face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, refine_landmarks=True)
            return True

        except Exception as e:
            print(f"âŒ æª¢æ¸¬å™¨åˆå§‹åŒ–å¤±æ•—: {e}")
            return False

    def base64_to_image(self, base64_string):
        """å°‡base64å­—ç¬¦ä¸²è½‰æ›ç‚ºOpenCVåœ–åƒ"""
        try:
            if base64_string.startswith('data:image'):
                base64_string = base64_string.split(',')[1]

            image_data = base64.b64decode(base64_string)
            image_pil = Image.open(io.BytesIO(image_data))

            if image_pil.mode != 'RGB':
                image_pil = image_pil.convert('RGB')

            image_array = np.array(image_pil)
            image_bgr = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)
            return image_bgr
        except Exception as e:
            raise Exception(f"base64è½‰æ›åœ–åƒå¤±æ•—: {e}")

    def image_to_base64(self, image):
        """å°‡OpenCVåœ–åƒè½‰æ›ç‚ºbase64å­—ç¬¦ä¸²"""
        try:
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image_pil = Image.fromarray(image_rgb)

            buffer = io.BytesIO()
            image_pil.save(buffer, format='PNG')
            buffer.seek(0)

            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            return f"data:image/png;base64,{image_base64}"
        except Exception as e:
            raise Exception(f"åœ–åƒè½‰æ›base64å¤±æ•—: {e}")

    def safe_face_detection(self, image):
        """å®‰å…¨çš„äººè‡‰æª¢æ¸¬"""
        try:
            if self.face_app is None:
                return []
            faces = self.face_app.get(image)
            return faces if faces else []
        except Exception as e:
            print(f"âŒ äººè‡‰æª¢æ¸¬å¤±æ•—: {e}")
            return []

    def safe_mediapipe_detection(self, image_rgb):
        """å®‰å…¨çš„MediaPipeæª¢æ¸¬"""
        try:
            if self.face_mesh is None:
                return None
            results = self.face_mesh.process(image_rgb)
            return results
        except Exception as e:
            print(f"âŒ MediaPipe æª¢æ¸¬å¤±æ•—: {e}")
            return None

    def detect_faces_with_landmarks(self, image):
        """æª¢æ¸¬äººè‡‰ä¸¦è¿”å›ç‰¹å¾µé»"""
        h, w = image.shape[:2]
        img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        faces = self.safe_face_detection(image)
        if not faces:
            return []

        results = self.safe_mediapipe_detection(img_rgb)
        if not results or not results.multi_face_landmarks:
            return []

        landmarks = results.multi_face_landmarks[0]

        face_data = []
        for face in faces:
            bbox = face.bbox
            face_rect = {
                'left': int(bbox[0]),
                'top': int(bbox[1]),
                'width': int(bbox[2] - bbox[0]),
                'height': int(bbox[3] - bbox[1])
            }

            face_data.append({
                'rect': face_rect,
                'landmarks': landmarks,
                'image_size': (w, h)
            })

        return face_data

    def get_all_face_regions(self, landmarks, image_size):
        """ç²å–æ‰€æœ‰é¢éƒ¨å€åŸŸ"""
        w, h = image_size

        organ_landmarks = {
            FaceRegion.BRAIN: 10,
            FaceRegion.LUNG: 8,
            FaceRegion.HEART: 168,
            FaceRegion.LIVER: 197,
            FaceRegion.SPLEEN: 4,
            FaceRegion.LEFT_KIDNEY: 411,
            FaceRegion.RIGHT_KIDNEY: 187,
            FaceRegion.LEFT_STOMACH: 294,
            FaceRegion.RIGHT_STOMACH: 64,
            FaceRegion.LEFT_LONG: 330,
            FaceRegion.RIGHT_LONG: 101,
            FaceRegion.BLADDER: 164,
            FaceRegion.LEFT_EYE_WHITE: 33,
            FaceRegion.RIGHT_EYE_WHITE: 263,
            FaceRegion.CHIN: 175,
        }

        organ_crop_sizes = {
            FaceRegion.BRAIN: (100, 100),  # ä»80x80å¢åŠ åˆ°100x100
            FaceRegion.LUNG: (35, 35),  # ä»20x20å¢åŠ åˆ°35x35
            FaceRegion.HEART: (35, 35),  # ä»20x20å¢åŠ åˆ°35x35
            FaceRegion.LIVER: (35, 35),  # ä»20x20å¢åŠ åˆ°35x35
            FaceRegion.SPLEEN: (35, 35),  # ä»20x20å¢åŠ åˆ°35x35
            FaceRegion.LEFT_KIDNEY: (35, 35),  # ä»20x20å¢åŠ åˆ°35x35
            FaceRegion.RIGHT_KIDNEY: (35, 35),  # ä»20x20å¢åŠ åˆ°35x35
            FaceRegion.LEFT_STOMACH: (35, 35),  # ä»20x20å¢åŠ åˆ°35x35
            FaceRegion.RIGHT_STOMACH: (35, 35),  # ä»20x20å¢åŠ åˆ°35x35
            FaceRegion.LEFT_LONG: (35, 35),  # ä»20x20å¢åŠ åˆ°35x35
            FaceRegion.RIGHT_LONG: (35, 35),  # ä»20x20å¢åŠ åˆ°35x35
            FaceRegion.BLADDER: (35, 35),  # ä»20x20å¢åŠ åˆ°35x35
            FaceRegion.LEFT_EYE_WHITE: (30, 15),  # ä¿æŒä¸å˜
            FaceRegion.RIGHT_EYE_WHITE: (30, 15),  # ä¿æŒä¸å˜
            FaceRegion.CHIN: (50, 40),  # ä»40x30å¢åŠ åˆ°50x40
        }

        regions = {}
        for organ, idx in organ_landmarks.items():
            pt = landmarks.landmark[idx]
            cx, cy = int(pt.x * w), int(pt.y * h)

            crop_w, crop_h = organ_crop_sizes.get(organ, (20, 20))
            x1 = max(cx - crop_w // 2, 0)
            y1 = max(cy - crop_h // 2, 0)
            x2 = min(cx + crop_w // 2, w)
            y2 = min(cy + crop_h // 2, h)

            regions[organ] = (x1, y1, x2 - x1, y2 - y1)

        return regions

    def analyze_skin_color_for_region(self, image, region_rect):
        """åˆ†æç‰¹å®šå€åŸŸçš„è†šè‰²"""
        x, y, w, h = region_rect

        x = max(0, x)
        y = max(0, y)
        w = min(image.shape[1] - x, w)
        h = min(image.shape[0] - y, h)

        if w <= 0 or h <= 0:
            return (153, 134, 117)

        region = image[y:y + h, x:x + w]
        blurred = cv2.GaussianBlur(region, (7, 7), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        avg_brightness = np.mean(hsv[:, :, 2])

        if avg_brightness < 50:
            lower_skin = np.array([0, 5, 20])
            upper_skin = np.array([40, 255, 255])
        else:
            lower_skin = np.array([0, 10, 40])
            upper_skin = np.array([40, 255, 255])

        skin_mask = cv2.inRange(hsv, lower_skin, upper_skin)

        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        skin_mask = cv2.morphologyEx(skin_mask, cv2.MORPH_CLOSE, kernel)
        skin_mask = cv2.morphologyEx(skin_mask, cv2.MORPH_OPEN, kernel)

        if cv2.countNonZero(skin_mask) < (w * h * 0.1):
            lower_skin_loose = np.array([0, 8, 30])
            upper_skin_loose = np.array([50, 255, 255])
            skin_mask = cv2.inRange(hsv, lower_skin_loose, upper_skin_loose)

            if cv2.countNonZero(skin_mask) == 0:
                skin_mask = np.ones((h, w), dtype=np.uint8) * 255

        skin_region = cv2.bitwise_and(blurred, blurred, mask=skin_mask)
        mean_color = cv2.mean(skin_region, skin_mask)

        return mean_color[:3]

    def analyze_cyan_subdivision_simple(self, mean_color, region=None):
        """
        ç®€åŒ–ç‰ˆé’è‰²ç´°åˆ†ï¼šåªå€åˆ†é’ç¶ å’Œé’é»‘
        """
        b, g, r = mean_color

        brightness = (r + g + b) / 3.0
        total_color = r + g + b

        if total_color == 0:
            return None

        green_ratio = g / total_color
        blue_ratio = b / total_color
        red_ratio = r / total_color

        # é’è‰²ç³»åˆ¤æ–·åŸºæº–
        is_cyan_base = (
                (blue_ratio > red_ratio and blue_ratio > 0.35) or
                (green_ratio > red_ratio and green_ratio > 0.35 and blue_ratio > 0.3)
        )

        if not is_cyan_base:
            return None

        # æ ¸å¿ƒåˆ¤æ–·é‚è¼¯ï¼šäº®åº¦ + ç¶ è—æ¯”ä¾‹
        gb_ratio = green_ratio / blue_ratio if blue_ratio > 0 else 0
        brightness_threshold = 85
        gb_threshold = 1.05

        # é’ç¶ ï¼šè¼ƒäº®ä¸”ç¶ è‰²æ¯”ä¾‹è¼ƒé«˜
        if brightness > brightness_threshold and gb_ratio > gb_threshold:
            return SkinCondition.CYAN_GREEN
        # é’é»‘ï¼šè¼ƒæš—æˆ–è—è‰²æ¯”ä¾‹è¼ƒé«˜
        else:
            return SkinCondition.CYAN_BLACK

    def diagnose_skin_condition(self, mean_color, region=None):
        """æ ¹æ“šRGBå€¼åˆ¤æ–·è†šè‰²ç‹€æ…‹ - åˆ é™¤é¢éƒ¨å‘é»„ï¼Œä¿ç•™çœ¼ç™½å‘é»„"""
        b, g, r = mean_color

        # ç‰¹æ®Šè™•ç†çœ¼ç™½å€åŸŸ - ä¿ç•™çœ¼ç™½å‘é»„è¯†åˆ«
        if region in [FaceRegion.LEFT_EYE_WHITE, FaceRegion.RIGHT_EYE_WHITE]:
            total_color = r + g + b
            if total_color > 0:
                yellow_ratio = (r + g) / (2 * total_color)
                blue_ratio = b / total_color

                if yellow_ratio > 0.6 and blue_ratio < 0.25 and g > 120:
                    return SkinCondition.YELLOW

            return SkinCondition.NORMAL

        # åŸºæœ¬åƒæ•¸è¨ˆç®—
        brightness = (r + g + b) / 3.0
        max_color = max(r, g, b)
        min_color = min(r, g, b)
        saturation = (max_color - min_color) / max_color if max_color > 0 else 0

        total_color = r + g + b
        if total_color > 0:
            red_ratio = r / total_color
            green_ratio = g / total_color
            blue_ratio = b / total_color
        else:
            red_ratio = green_ratio = blue_ratio = 0.33

        # è·å–å…·ä½“ä½ç½®æè¿°
        position_desc = self.get_face_position_description(region)

        # é¢éƒ¨åŒºåŸŸå¼‚å¸¸æ£€æµ‹ - æ·»åŠ ä½ç½®ä¿¡æ¯è¾“å‡º
        if brightness < 65:
            print(f"{region.value}({position_desc}): RGB({int(r)},{int(g)},{int(b)}) -> ç™¼é»‘")
            return SkinCondition.DARK
        elif brightness > 200 and min_color > 150 and saturation < 0.1:
            print(f"{region.value}({position_desc}): RGB({int(r)},{int(g)},{int(b)}) -> ç™¼ç™½")
            return SkinCondition.PALE
        elif red_ratio > 0.50 and r > 175 and saturation > 0.17:
            print(f"{region.value}({position_desc}): RGB({int(r)},{int(g)},{int(b)}) -> ç™¼ç´…")
            return SkinCondition.RED

        # é’è‰²ç³»åˆ¤æ–·
        cyan_result = self.analyze_cyan_subdivision_simple(mean_color, region)
        if cyan_result:
            print(f"{region.value}({position_desc}): RGB({int(r)},{int(g)},{int(b)}) -> {cyan_result.value}")
            return cyan_result

        return SkinCondition.NORMAL

    def get_condition_colors(self):
        """ç®€åŒ–ç‰ˆé¡è‰²æ˜ å°„"""
        return {
            SkinCondition.NORMAL: (0, 255, 0),  # ç¶ è‰²
            SkinCondition.DARK: (0, 0, 139),  # æ·±è—
            SkinCondition.RED: (0, 0, 255),  # ç´…è‰²
            SkinCondition.PALE: (255, 255, 255),  # ç™½è‰²
            SkinCondition.YELLOW: (0, 255, 255),  # é»ƒè‰²
            SkinCondition.CYAN_GREEN: (255, 255, 0),  # é’ç¶ è‰²
            SkinCondition.CYAN_BLACK: (128, 128, 0),  # é’é»‘è‰²
        }

    def generate_cyan_report(self):
        """ç”Ÿæˆç®€åŒ–ç‰ˆé’è‰²å ±å‘Š"""
        cyan_green_regions = []
        cyan_black_regions = []

        for region, condition in self.diagnosis_results.items():
            if condition == SkinCondition.CYAN_GREEN:
                cyan_green_regions.append(region.value)
            elif condition == SkinCondition.CYAN_BLACK:
                cyan_black_regions.append(region.value)

        total_cyan = len(cyan_green_regions) + len(cyan_black_regions)

        if total_cyan == 0:
            return None

        return {
            "é’ç¶ å€åŸŸ": cyan_green_regions,
            "é’é»‘å€åŸŸ": cyan_black_regions,
            "é’ç¶ æ•¸é‡": len(cyan_green_regions),
            "é’é»‘æ•¸é‡": len(cyan_black_regions),
            "ç¸½é’è‰²å€åŸŸ": total_cyan,
            "ä¸»è¦é¡å‹": "é’ç¶ " if len(cyan_green_regions) > len(cyan_black_regions) else "é’é»‘"
        }

    def draw_face_regions(self, image):
        """åœ¨åœ–åƒä¸Šç¹ªè£½é¢éƒ¨å€åŸŸ"""
        if not self.face_regions:
            return image

        annotated_image = image.copy()
        condition_colors = self.get_condition_colors()

        for region, region_rect in self.face_regions.items():
            x, y, w, h = region_rect
            condition = self.diagnosis_results.get(region, SkinCondition.NORMAL)
            color = condition_colors.get(condition, (0, 255, 0))

            thickness = 3 if condition != SkinCondition.NORMAL else 2
            cv2.rectangle(annotated_image, (x, y), (x + w, y + h), color, thickness)

            label_text = condition.value
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.4
            font_thickness = 1

            (text_width, text_height), baseline = cv2.getTextSize(label_text, font, font_scale, font_thickness)

            cv2.rectangle(annotated_image,
                          (x, y - text_height - 5),
                          (x + text_width + 5, y),
                          color, -1)

            text_color = (0, 0, 0) if condition in [SkinCondition.PALE, SkinCondition.YELLOW,
                                                    SkinCondition.CYAN_GREEN] else (255, 255, 255)
            cv2.putText(annotated_image, label_text, (x + 2, y - 2),
                        font, font_scale, text_color, font_thickness, cv2.LINE_AA)

        return annotated_image

    def draw_abnormal_regions_on_original(self, image):
        """åœ¨åŸåœ–ä¸Šåªæ¨™è¨»ç•°å¸¸å€åŸŸ"""
        if not self.face_regions:
            return image, 0

        annotated_image = image.copy()
        condition_colors = self.get_condition_colors()

        abnormal_count = 0
        for region, region_rect in self.face_regions.items():
            condition = self.diagnosis_results.get(region, SkinCondition.NORMAL)

            if condition == SkinCondition.NORMAL:
                continue

            abnormal_count += 1
            x, y, w, h = region_rect
            color = condition_colors.get(condition, (0, 0, 255))

            thickness = 4
            cv2.rectangle(annotated_image, (x, y), (x + w, y + h), color, thickness)

            label_text = f"{region.value}: {condition.value}"
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.6
            font_thickness = 2

            (text_width, text_height), baseline = cv2.getTextSize(label_text, font, font_scale, font_thickness)

            label_bg_height = text_height + 10
            label_bg_width = text_width + 10

            label_y = max(y - label_bg_height, label_bg_height)
            label_x = min(x, image.shape[1] - label_bg_width)

            cv2.rectangle(annotated_image,
                          (label_x, label_y - label_bg_height),
                          (label_x + label_bg_width, label_y),
                          color, -1)

            text_y = label_y - 5
            text_x = label_x + 5
            cv2.putText(annotated_image, label_text, (text_x, text_y),
                        font, font_scale, (255, 255, 255), font_thickness, cv2.LINE_AA)

        return annotated_image, abnormal_count

    def grid_analysis(self, image):
        """åœ–åƒæ ¼ç‹€åˆ†æ"""
        h, w = image.shape[:2]
        if h < 400 or w < 400:
            scale = max(400 / h, 400 / w)
            image = cv2.resize(image, (int(w * scale), int(h * scale)))

        grid_rows, grid_cols = 100, 100
        cell_h, cell_w = image.shape[0] // grid_rows, image.shape[1] // grid_cols
        avg_all = image.mean(axis=(0, 1)).astype(np.uint8)
        out_img = np.zeros_like(image)
        replace_img = image.copy()

        for row in range(grid_rows):
            for col in range(grid_cols):
                y1, y2 = row * cell_h, min((row + 1) * cell_h, image.shape[0])
                x1, x2 = col * cell_w, min((col + 1) * cell_w, image.shape[1])
                cell = image[y1:y2, x1:x2]
                if cell.size == 0:
                    continue
                avg = cell.mean(axis=(0, 1)).astype(np.uint8)
                bright = avg.mean()
                out_img[y1:y2, x1:x2] = avg
                if bright < 122:
                    cv2.rectangle(out_img, (x1, y1), (x2, y2), (0, 0, 255), 2)
                    replace_img[y1:y2, x1:x2] = avg_all

        for i in range(1, grid_rows):
            cv2.line(out_img, (0, i * cell_h), (image.shape[1], i * cell_h), (0, 0, 0), 1)
        for j in range(1, grid_cols):
            cv2.line(out_img, (j * cell_w, 0), (j * cell_w, image.shape[0]), (0, 0, 0), 1)

        return {
            'original': image,
            'grid': out_img,
            'dark_blocks': replace_img
        }

    def analyze_from_base64(self, base64_string):
        """å¾base64å­—ç¬¦ä¸²åˆ†æåœ–åƒ"""
        try:
            self.diagnosis_results.clear()
            self.face_regions.clear()
            self.current_face_rect = None

            image = self.base64_to_image(base64_string)
            face_data = self.detect_faces_with_landmarks(image)

            if not face_data:
                return {
                    "success": False,
                    "error": "æœªèƒ½æª¢æ¸¬åˆ°é¢éƒ¨ç‰¹å¾µé»ã€‚\n\nè«‹ç¢ºä¿ï¼š\nâ€¢ è‡‰éƒ¨å®Œæ•´ä¸”æ¸…æ™°å¯è¦‹\nâ€¢ å…‰ç·šå……è¶³ä¸”å‡å‹»\nâ€¢ é¿å…éæš—æˆ–é€†å…‰\nâ€¢ æ­£å°é¡é ­\n\nèª¿æ•´å¾Œé‡æ–°æ‹æ”æˆ–é¸æ“‡ç…§ç‰‡ã€‚",
                    "original_image": base64_string,
                    "annotated_image": None,
                    "abnormal_only_image": None,
                    "overall_color": None,
                    "region_results": None,
                    "grid_analysis": None,
                    "cyan_report": None
                }

            face_info = face_data[0]
            landmarks = face_info['landmarks']
            face_rect = face_info['rect']
            image_size = face_info['image_size']

            self.current_face_rect = (face_rect['left'], face_rect['top'],
                                      face_rect['width'], face_rect['height'])

            self.face_regions = self.get_all_face_regions(landmarks, image_size)



            # åˆ†ææ¯å€‹å€åŸŸ
            for region, region_rect in self.face_regions.items():
                mean_color = self.analyze_skin_color_for_region(image, region_rect)
                condition = self.diagnose_skin_condition(mean_color, region)
                self.diagnosis_results[region] = condition

            overall_color = self.analyze_skin_color_for_region(image, self.current_face_rect)
            annotated_image = self.draw_face_regions(image)
            abnormal_only_image, abnormal_count = self.draw_abnormal_regions_on_original(image)
            grid_results = self.grid_analysis(image)

            # ç”Ÿæˆé’è‰²åˆ†æå ±å‘Š
            cyan_report = self.generate_cyan_report()

            annotated_base64 = self.image_to_base64(annotated_image)
            abnormal_only_base64 = self.image_to_base64(abnormal_only_image)
            grid_base64 = self.image_to_base64(grid_results['grid'])
            dark_blocks_base64 = self.image_to_base64(grid_results['dark_blocks'])

            all_regions = {region.value: condition.value for region, condition in self.diagnosis_results.items()}
            abnormal_regions = {region.value: condition.value for region, condition in
                                self.diagnosis_results.items() if condition != SkinCondition.NORMAL}

            print("åˆ†æå®Œæˆï¼")
            if abnormal_count > 0:
                print(f"ç•°å¸¸å€åŸŸæ•¸é‡: {abnormal_count}")
            else:
                print("æ‰€æœ‰å€åŸŸè†šè‰²ç‹€æ…‹æ­£å¸¸ï¼ï¼ï¼")
            return {
                "success": True,
                "error": None,
                "original_image": base64_string,
                "annotated_image": annotated_base64,
                "abnormal_only_image": abnormal_only_base64,
                "abnormal_count": abnormal_count,
                "overall_color": {
                    "r": int(overall_color[2]),
                    "g": int(overall_color[1]),
                    "b": int(overall_color[0]),
                    "hex": f"#{int(overall_color[2]):02X}{int(overall_color[1]):02X}{int(overall_color[0]):02X}"
                },
                "all_region_results": all_regions,
                "region_results": abnormal_regions,
                "grid_analysis": {
                    "grid_image": grid_base64,
                    "dark_blocks_image": dark_blocks_base64
                },
                "cyan_report": cyan_report
            }

        except Exception as e:
            return {
                "success": False,
                "error": f"åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}",
                "original_image": base64_string,
                "annotated_image": None,
                "abnormal_only_image": None,
                "overall_color": None,
                "region_results": None,
                "grid_analysis": None,
                "cyan_report": None
            }


def save_base64_image(base64_string, output_path):
    """å°‡base64å­—ç¬¦ä¸²ä¿å­˜ç‚ºåœ–åƒæ–‡ä»¶"""
    try:
        if base64_string.startswith('data:image'):
            base64_string = base64_string.split(',')[1]

        image_data = base64.b64decode(base64_string)

        with open(output_path, 'wb') as f:
            f.write(image_data)

        return True
    except Exception as e:
        print(f"ä¿å­˜åœ–åƒå¤±æ•—ï¼š{e}")
        return False


def check_dependencies():
    """æª¢æŸ¥ç³»çµ±ä¾è³´åŒ…å®‰è£æƒ…æ³"""
    dependencies = {
        'opencv-python': 'cv2',
        'numpy': 'numpy',
        'pillow': 'PIL',
        'insightface': 'insightface',
        'mediapipe': 'mediapipe'
    }

    missing_packages = []

    for package_name, import_name in dependencies.items():
        try:
            __import__(import_name)
        except ImportError:
            print(f"âŒ {package_name} - æœªå®‰è£")
            missing_packages.append(package_name)

    if missing_packages:
        print(f"\nâš ï¸  ç¼ºå°‘ä¾è³´åŒ…: {', '.join(missing_packages)}")
        print("\nğŸ’¡ å®‰è£å‘½ä»¤:")
        print("pip install " + " ".join(missing_packages))
        return False
    else:
        return True





def simple_face_analysis(input_folder="images", output_folder="face_analysis_simple"):
    """
    ç®€åŒ–ç‰ˆé¢éƒ¨è†šè‰²åˆ†æï¼Œæ”¯æŒé’ç¶ é’é»‘è¨ºæ–·
    """

    if not check_dependencies():
        print("âŒ è«‹å…ˆå®‰è£ç¼ºå°‘çš„ä¾è³´åŒ…å¾Œå†é‹è¡Œ")
        return False

    os.makedirs(output_folder, exist_ok=True)

    print("ğŸ”§ åˆå§‹åŒ–åˆ†æå™¨...")
    analyzer = FaceSkinAnalyzer()

    if analyzer.face_app is None or analyzer.face_mesh is None:
        print("âŒ åˆ†æå™¨åˆå§‹åŒ–å¤±æ•—")
        return False

    success_count = 0
    fail_count = 0
    cyan_statistics = {
        "é’ç¶ å€åŸŸç¸½æ•¸": 0,
        "é’é»‘å€åŸŸç¸½æ•¸": 0,
        "æœ‰é’è‰²çš„åœ–åƒ": []
    }

    print(f"ğŸ“ è™•ç† {input_folder} è³‡æ–™å¤¾...")

    if not os.path.exists(input_folder):
        print(f"âŒ è³‡æ–™å¤¾ä¸å­˜åœ¨: {input_folder}")
        return False

    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

    if not image_files:
        print(f"âŒ æ²’æœ‰æ‰¾åˆ°åœ–åƒæ–‡ä»¶")
        return False

    print(f"ğŸ“Š æ‰¾åˆ° {len(image_files)} å€‹åœ–åƒæ–‡ä»¶")

    for filename in image_files:
        img_path = os.path.join(input_folder, filename)
        base_name = os.path.splitext(filename)[0]

        print(f"\nè™•ç†: {filename}")

        try:
            with open(img_path, 'rb') as f:
                image_data = f.read()

            base64_string = base64.b64encode(image_data).decode('utf-8')
            if filename.lower().endswith('.png'):
                base64_string = f"data:image/png;base64,{base64_string}"
            else:
                base64_string = f"data:image/jpeg;base64,{base64_string}"

            result = analyzer.analyze_from_base64(base64_string)

            if result["success"]:
                success_count += 1

                image_output_folder = os.path.join(output_folder, base_name)
                os.makedirs(image_output_folder, exist_ok=True)

                # ä¿å­˜åŸå§‹åœ–åƒ
                original_path = os.path.join(image_output_folder, f"{base_name}_original.jpg")
                with open(original_path, 'wb') as f:
                    f.write(image_data)

                # ä¿å­˜æ¨™è¨»åœ–åƒ
                if result["annotated_image"]:
                    annotated_path = os.path.join(image_output_folder, f"{base_name}_annotated.png")
                    save_base64_image(result["annotated_image"], annotated_path)

                if result.get("abnormal_only_image"):
                    abnormal_path = os.path.join(image_output_folder, f"{base_name}_abnormal_only.png")
                    save_base64_image(result["abnormal_only_image"], abnormal_path)

                # ä¿å­˜åˆ†æçµæœ
                json_path = os.path.join(image_output_folder, f"{base_name}_analysis.json")
                with open(json_path, 'w', encoding='utf-8') as f:
                    result_copy = result.copy()
                    result_copy["original_image"] = None
                    result_copy["annotated_image"] = None
                    result_copy["abnormal_only_image"] = None
                    result_copy["grid_analysis"] = None
                    json.dump(result_copy, f, ensure_ascii=False, indent=2)

                # çµ±è¨ˆé’è‰²ç³»
                cyan_report = result.get("cyan_report")
                if cyan_report:
                    cyan_statistics["é’ç¶ å€åŸŸç¸½æ•¸"] += cyan_report["é’ç¶ æ•¸é‡"]
                    cyan_statistics["é’é»‘å€åŸŸç¸½æ•¸"] += cyan_report["é’é»‘æ•¸é‡"]
                    cyan_statistics["æœ‰é’è‰²çš„åœ–åƒ"].append({
                        "æ–‡ä»¶å": filename,
                        "é’ç¶ å€åŸŸ": cyan_report["é’ç¶ å€åŸŸ"],
                        "é’é»‘å€åŸŸ": cyan_report["é’é»‘å€åŸŸ"]
                    })

                print(f"æˆåŠŸ: {filename}")

            else:
                fail_count += 1
                print(f"  âŒ å¤±æ•—: {filename} - {result['error']}")

        except Exception as e:
            fail_count += 1
            print(f"  âŒ éŒ¯èª¤: {filename} - {str(e)}")

    # ç”Ÿæˆæœ€çµ‚å ±å‘Š
    final_report = {
        "è™•ç†çµ±è¨ˆ": {
            "ç¸½åœ–åƒæ•¸": success_count + fail_count,
            "æˆåŠŸè™•ç†": success_count,
            "è™•ç†å¤±æ•—": fail_count,
            "æˆåŠŸç‡": f"{success_count / (success_count + fail_count) * 100:.1f}%" if (
                                                                                                  success_count + fail_count) > 0 else "0%"
        },
        "é’è‰²ç³»çµ±è¨ˆ": cyan_statistics,
        "è¼¸å‡ºè³‡æ–™å¤¾": output_folder
    }

    report_path = os.path.join(output_folder, "simple_analysis_report.json")
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(final_report, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… åˆ†æå®Œæˆï¼")
    print(f"ğŸ“Š çµ±è¨ˆ:")
    print(f"  - ç¸½åœ–åƒ: {success_count + fail_count}")
    print(f"  - æˆåŠŸè™•ç†: {success_count}")
    print(f"  - è™•ç†å¤±æ•—: {fail_count}")

    if cyan_statistics["é’ç¶ å€åŸŸç¸½æ•¸"] > 0 or cyan_statistics["é’é»‘å€åŸŸç¸½æ•¸"] > 0:
        print(f"\nğŸ” é’è‰²ç³»çµ±è¨ˆ:")
        print(f"  - é’ç¶ å€åŸŸç¸½æ•¸: {cyan_statistics['é’ç¶ å€åŸŸç¸½æ•¸']}")
        print(f"  - é’é»‘å€åŸŸç¸½æ•¸: {cyan_statistics['é’é»‘å€åŸŸç¸½æ•¸']}")
        print(f"  - æœ‰é’è‰²ç•°å¸¸çš„åœ–åƒ: {len(cyan_statistics['æœ‰é’è‰²çš„åœ–åƒ'])}")

        for img_info in cyan_statistics["æœ‰é’è‰²çš„åœ–åƒ"][:3]:  # åªé¡¯ç¤ºå‰3å€‹
            print(f"    â””â”€ {img_info['æ–‡ä»¶å']}: é’ç¶ {len(img_info['é’ç¶ å€åŸŸ'])}å€‹ é’é»‘{len(img_info['é’é»‘å€åŸŸ'])}å€‹")

    print(f"\nğŸ“ çµæœä¿å­˜åœ¨: {output_folder}")
    print(f"ğŸ“„ å ±å‘Š: {report_path}")

    return True


def analyze_face_from_base64(base64_string):
    """ä¾¿æ·å‡½æ•¸ï¼šå¾base64å­—ç¬¦ä¸²åˆ†æé¢éƒ¨è†šè‰²"""
    analyzer = FaceSkinAnalyzer()
    return analyzer.analyze_from_base64(base64_string)


def analyze_face_from_file(file_path):
    """ä¾¿æ·å‡½æ•¸ï¼šå¾æ–‡ä»¶è·¯å¾‘åˆ†æé¢éƒ¨è†šè‰²"""
    try:
        with open(file_path, 'rb') as f:
            image_data = f.read()

        base64_string = base64.b64encode(image_data).decode('utf-8')

        if file_path.lower().endswith('.png'):
            base64_string = f"data:image/png;base64,{base64_string}"
        elif file_path.lower().endswith(('.jpg', '.jpeg')):
            base64_string = f"data:image/jpeg;base64,{base64_string}"
        else:
            base64_string = f"data:image/png;base64,{base64_string}"

        analyzer = FaceSkinAnalyzer()
        return analyzer.analyze_from_base64(base64_string)

    except Exception as e:
        return {
            "success": False,
            "error": f"è®€å–æ–‡ä»¶å¤±æ•—ï¼š{str(e)}",
            "original_image": None,
            "annotated_image": None,
            "abnormal_only_image": None,
            "overall_color": None,
            "region_results": None,
            "grid_analysis": None,
            "cyan_report": None
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    os.environ['OMP_NUM_THREADS'] = '1'
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # å±è”½TensorFlowä¿¡æ¯

    # å±è”½æ‰€æœ‰ç›¸å…³è­¦å‘Š
    warnings.filterwarnings("ignore", message=".*CUDAExecutionProvider.*")
    warnings.filterwarnings("ignore", message=".*onnxruntime.*")
    warnings.filterwarnings("ignore", message=".*rcond.*")
    warnings.filterwarnings("ignore", category=FutureWarning)
    warnings.filterwarnings("ignore", category=UserWarning)

    print("é¢éƒ¨è†šè‰²åˆ†æç³»çµ±")

    # è™•ç†åœ–åƒ
    if os.path.exists("images"):
        image_count = len([f for f in os.listdir('images') if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
        print(f"\nğŸ“ ç™¼ç¾ 'images' è³‡æ–™å¤¾ï¼ŒåŒ…å« {image_count} å¼µåœ–åƒ")

        if image_count > 0:
            print("\n2ï¸âƒ£ é–‹å§‹è™•ç†åœ–åƒ...")

            result = simple_face_analysis(
                input_folder="images",
                output_folder="face_analysis_simple"
            )

            if result:
                print(f"\nğŸ‰ è™•ç†å®Œæˆ!")
            else:
                print(f"\nâŒ è™•ç†å¤±æ•—")

        else:
            print("ğŸ“‚ 'images' è³‡æ–™å¤¾ç‚ºç©ºï¼Œè«‹æ·»åŠ åœ–åƒæ–‡ä»¶ã€‚")
    else:
        print("\nğŸ“‚ è«‹å‰µå»º 'images' è³‡æ–™å¤¾ä¸¦æ”¾å…¥åœ–åƒæ–‡ä»¶ã€‚")
        print("ç³»çµ±å°‡åŸ·è¡Œ:")
        print("1. é’è‰²é‚è¼¯æ¸¬è©¦")
        print("2. é¢éƒ¨å€åŸŸè­˜åˆ¥")
        print("3. é’ç¶ ã€é’é»‘è¨ºæ–·")
        print("4. ç”Ÿæˆæ¨™è¨»åœ–åƒ")
        print("5. è¼¸å‡ºåˆ†æå ±å‘Š")